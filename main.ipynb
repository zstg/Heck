{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-dd66exon\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-dd66exon\n",
      "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: speechrecognition in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (3.14.1)\n",
      "Requirement already satisfied: transformers in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (4.49.0)\n",
      "Requirement already satisfied: nltk in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: moviepy==1.0.3 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (1.0.3)\n",
      "Requirement already satisfied: tabulate in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: ollama in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (0.4.7)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from moviepy==1.0.3) (4.4.2)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from moviepy==1.0.3) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from moviepy==1.0.3) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from moviepy==1.0.3) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from moviepy==1.0.3) (2.1.3)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from moviepy==1.0.3) (2.32.3)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from moviepy==1.0.3) (0.1.10)\n",
      "Requirement already satisfied: more-itertools in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from openai-whisper==20240930) (10.6.0)\n",
      "Requirement already satisfied: numba in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from openai-whisper==20240930) (0.61.0)\n",
      "Requirement already satisfied: tiktoken in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from openai-whisper==20240930) (0.9.0)\n",
      "Requirement already satisfied: torch in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from openai-whisper==20240930) (2.6.0)\n",
      "Requirement already satisfied: triton>=2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from openai-whisper==20240930) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from speechrecognition) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from transformers) (0.29.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: click in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from ollama) (2.10.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: anyio in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.2.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from imageio<3.0,>=2.5->moviepy==1.0.3) (11.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2.3.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from numba->openai-whisper==20240930) (0.44.0)\n",
      "Requirement already satisfied: networkx in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: setuptools in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/gitpod/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/openai/whisper.git speechrecognition transformers nltk moviepy==1.0.3 tabulate ollama ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Cleaning up old version at /usr/local/lib/ollama\n",
      ">>> Installing ollama to /usr/local\n",
      ">>> Downloading Linux amd64 bundle\n",
      "######################################################################## 100.0%#################                          66.9%                 70.1%################               82.1%\n",
      ">>> Adding ollama user to video group...\n",
      ">>> Adding current user to ollama group...\n",
      ">>> Creating ollama systemd service...\n",
      "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
      "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
      ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
      ">>> Install complete. Run \"ollama\" from the command line.\n"
     ]
    }
   ],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: listen tcp 127.0.0.1:11434: bind: address already in use\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \u001b[K\n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \u001b[K\n",
      "pulling 491dfa501e59... 100% ▕████████████████▏  801 B                         \u001b[K\n",
      "pulling ed11eda7790d... 100% ▕████████████████▏   30 B                         \u001b[K\n",
      "pulling 42347cd80dc8... 100% ▕████████████████▏  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "from subprocess import Popen\n",
    "process = Popen(\"ollama serve\", shell=True)\n",
    "!ollama pull mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import whisper\n",
    "import ollama\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_from_video(video_path, audio_output_path=\"output.wav\"):\n",
    "    \"\"\"Extracts audio from video and saves it as a WAV file.\"\"\"\n",
    "    try:\n",
    "        video = mp.VideoFileClip(video_path)\n",
    "        audio = video.audio\n",
    "        audio.write_audiofile(audio_output_path, logger=None)\n",
    "        print(f\"Audio extracted to {audio_output_path}\")\n",
    "        return audio_output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting audio: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Transcribes the extracted audio using Whisper AI.\"\"\"\n",
    "    try:\n",
    "        model = whisper.load_model(\"base\")\n",
    "        result = model.transcribe(audio_path)\n",
    "        print(\"Transcription completed.\")\n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tasks_with_llm(transcription):\n",
    "    \"\"\"Uses a local LLM (via Ollama) to extract structured tasks from a meeting transcript.\"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are an AI assistant extracting actionable tasks from meeting transcripts.\n",
    "    - Identify tasks assigned to real people only (ignore 'it', 'we', 'someone', etc.).\n",
    "    - Rewrite tasks in clear English.\n",
    "    - Extract deadlines if mentioned in YYYY-MM-DD format; otherwise, use 'N/A'.\n",
    "    - Output the result as a valid JSON array with \"assigned_to\", \"task\", and \"deadline\".\n",
    "    - Output the user tasks in bullet points.\n",
    "    - Ensure that the language is brief, formal and professional.\n",
    "    - Output in valid Markdown format.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"Meeting transcript:\\n\\n{transcription}\\n\\nExtract tasks as JSON.\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"mistral\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        tasks = json.loads(response[\"message\"][\"content\"])\n",
    "        return tasks\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: LLM returned invalid JSON.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meeting_function(video_path):\n",
    "    \"\"\"Main function to process a meeting video and generate a task summary.\"\"\"\n",
    "    print(\"Step 1: Extracting audio...\")\n",
    "    audio_path = extract_audio_from_video(video_path)\n",
    "    if not audio_path:\n",
    "        return \"Failed to extract audio from the video.\"\n",
    "\n",
    "    print(\"Step 2: Transcribing audio to text...\")\n",
    "    transcription = transcribe_audio(audio_path)\n",
    "    if not transcription:\n",
    "        os.remove(audio_path)\n",
    "        return \"Failed to transcribe audio.\"\n",
    "\n",
    "    print(\"Step 3: Extracting tasks with LLM...\")\n",
    "    tasks = extract_tasks_with_llm(transcription)  # This returns JSON data btw\n",
    "\n",
    "    table_data = []\n",
    "    for task in tasks:\n",
    "        table_data.append([task['assigned_to'], task['task'], task['deadline']])\n",
    "\n",
    "    table_output = tabulate(table_data, headers=[\"Assigned To\", \"Task\", \"Deadline\"], tablefmt=\"pipe\")\n",
    "\n",
    "    if os.path.exists(audio_path):\n",
    "        os.remove(audio_path)\n",
    "        print(f\"Cleaned up temporary file: {audio_path}\")\n",
    "\n",
    "    final_output = f\"\"\"\n",
    "    **AI-Powered Meeting Summarization and Task Assignment**\n",
    "\n",
    "    **Full Meeting Transcript:**\n",
    "    {transcription}\n",
    "\n",
    "    **Action Items & Schedule:**\n",
    "    {table_output}\n",
    "    \"\"\"\n",
    "\n",
    "    with open(\"meeting_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(final_output)\n",
    "\n",
    "    print(\"Summary saved to 'meeting_summary.txt'\")\n",
    "    #return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Create file upload widget\n",
    "upload_button = widgets.FileUpload(\n",
    "    accept='.mp4',  # Accept only MP4 files\n",
    "    multiple=False  # Allow only single file upload\n",
    ")\n",
    "\n",
    "# Create a button to trigger processing\n",
    "process_button = widgets.Button(description=\"Process Video\")\n",
    "\n",
    "# Function to handle file upload and processing\n",
    "def on_upload_change(change):\n",
    "    if upload_button.value:\n",
    "        uploaded_file = list(upload_button.value.values())[0]\n",
    "        file_name = uploaded_file['metadata']['name']\n",
    "        with open(file_name, 'wb') as f:\n",
    "            print(\"FIle being uploaded\")\n",
    "            f.write(uploaded_file['content'])\n",
    "        print(f\"File '{file_name}' uploaded successfully.\")\n",
    "        process_button.disabled = False\n",
    "\n",
    "def on_process_button_clicked(b):\n",
    "    uploaded_file = list(upload_button.value.values())[0]\n",
    "    file_name = uploaded_file['metadata']['name']\n",
    "    meeting_function(file_name)\n",
    "    os.remove(file_name)\n",
    "\n",
    "upload_button.observe(on_upload_change, names='value')\n",
    "process_button.on_click(on_process_button_clicked)\n",
    "\n",
    "# Initially disable the process button\n",
    "process_button.disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4e40c9d0714bae8c1c5504560acf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.mp4', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83d1a5cd4df4454b7528a27ee2e8def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process Video', disabled=True, style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(upload_button)\n",
    "display(process_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Extracting audio...\n",
      "Audio extracted to output.wav\n",
      "Step 2: Transcribing audio to text...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed.\n",
      "Step 3: Extracting tasks with LLM...\n",
      "Error: LLM returned invalid JSON.\n",
      "Cleaned up temporary file: output.wav\n",
      "Summary saved to 'meeting_summary.txt'\n"
     ]
    }
   ],
   "source": [
    "meeting_function('VID-20250307-WA0004.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully unindented content and saved to 'unindented_meeting_summary.txt'\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**AI-Powered Meeting Summarization and Task Assignment**\n",
       "\n",
       "\n",
       "**Full Meeting Transcript:**\n",
       "\n",
       "Boss, alright team, let's keep this shot into the point, we've got 5 minutes. Adam, I need you to analyze last week's sales reports and identify any unusual trends. Take the next star, summarize the key points and send me an email by 11A. Alex, you're inclined for lots. Reach out to the top 3 priority clients and get updates on their pending deals. Keep it brief, log everything in the CRM and update me before lunch. Smith, focus on inventory checks. I need a status report on stock levels by 2PM, especially on the top selling items. If there's any shortage, flag it immediately. Maxwell, work on the present, work on the marketing presentation for Friday's meeting. You've got the morning to draft it, make sure it's clear and data backed. I'll review it at 3PM. That's it. No delays, no excuses. If anything comes up, let me know. Now, get to work.\n",
       "\n",
       "**Action Items & Schedule:**\n",
       "\n",
       "| Assigned To   | Task   | Deadline   |\n",
       "|---------------|--------|------------|\n",
       "| Alex | Analyse last week's sales reports and identify trends | 24-6-25 |\n",
       "| Adam | Summarise key points, identify unusual trends, send email by 11 AM | 26-6-25  |\n",
       "| Adam | Reach out to top 3 clients and get updates | 26-6-25 |\n",
       "| Smith | Inventory checks before 2pm | 26-6-25 |\n",
       "| Maxwell | Work on marketing presentation | 28-6-25 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def unindent_file(input_file, output_file):\n",
    "    try:\n",
    "        with open(input_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_file}' not found.\")\n",
    "        return\n",
    "\n",
    "    unindented_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].rstrip()\n",
    "        unindented_line = re.sub(r'^ {2,}|^\\t', '', line)\n",
    "        unindented_lines.append(unindented_line)\n",
    "\n",
    "        if line.endswith(\"**\"):\n",
    "            unindented_lines.append(\"\") #add empty line\n",
    "        i += 1\n",
    "\n",
    "    try:\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write('\\n'.join(unindented_lines))\n",
    "        print(f\"Successfully unindented content and saved to '{output_file}'\")\n",
    "        # display(Markdown(f\"## unindented_meeting_summary.txt\"))\n",
    "        with open(output_file, 'r') as f:\n",
    "          display(Markdown(f.read()))\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while writing to the output file: {e}\")\n",
    "\n",
    "unindent_file('meeting_summary.txt', 'unindented_meeting_summary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
